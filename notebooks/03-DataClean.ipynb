{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e78317-d749-452b-8c6f-ee59f0cdf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7551903-f48e-46ee-8575-72d2158c405b",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61d1b4-6496-471a-817a-8a1e2cab3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLUMN = 'BA_ID'\n",
    "RESOURCES = [\n",
    "    (\n",
    "        'P',                                 # ID prefix\n",
    "        'portal',                            # category\n",
    "        'portals-metadata.json',             # metadata file\n",
    "        'portals-reports.json',              # report file\n",
    "        'portals-merged.json'                # merged file\n",
    "    ),\n",
    "    (\n",
    "        'V',                                 # ID prefix\n",
    "        'visualization',                     # category\n",
    "        'visualizations-metadata.json',      # metadata file\n",
    "        'visualizations-reports.json',       # report file\n",
    "        'visualizations-merged.json'         # merged file\n",
    "    ),\n",
    "    (\n",
    "        'J',                                 # ID prefix\n",
    "        'journal',                           # category\n",
    "        'journals-metadata.json',            # metadata file\n",
    "        'journals-reports.json',             # report file\n",
    "        'journals-merged.json'               # merged file\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430faee-d8ff-46e1-a551-4b999540b1bd",
   "metadata": {},
   "source": [
    "## Add `BA_ID` If Missing\n",
    "We want to provide unique ids to individual resources. We name the column after \"*B*iomedical *A*ccessibility.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516e1ca-db75-4c0e-b6b3-25c08154275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    id_prefix,\n",
    "    category,\n",
    "    metadata_file,\n",
    "    report_file,\n",
    "    merged_file\n",
    ") in RESOURCES:\n",
    "    \n",
    "    metadata_path = f'../output/{metadata_file}'\n",
    "    report_path = f'../output/{report_file}'\n",
    "    merged_path = f'../output/{merged_file}'\n",
    "    \n",
    "    meta_df = pd.read_json(metadata_path)\n",
    "    repo_df = pd.read_json(report_path)\n",
    "\n",
    "    if ID_COLUMN not in meta_df and ID_COLUMN not in repo_df:\n",
    "        \"\"\"\n",
    "        Add `BA_ID`\n",
    "        \"\"\"\n",
    "        meta_df[ID_COLUMN] = meta_df.index + 1\n",
    "        meta_df[ID_COLUMN] = id_prefix +  meta_df[ID_COLUMN].astype(str).str.zfill(6)\n",
    "        \n",
    "        repo_df[ID_COLUMN] = repo_df.index + 1\n",
    "        repo_df[ID_COLUMN] = id_prefix +  repo_df[ID_COLUMN].astype(str).str.zfill(6)\n",
    "        \n",
    "        meta_df.to_json(metadata_path, orient=\"records\")\n",
    "        repo_df.to_json(report_path, orient=\"records\")\n",
    "    else:\n",
    "        print(f'The {category} files already have column IDs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386164f-e43a-4f58-8f0c-597d00ed9195",
   "metadata": {},
   "source": [
    "## Merge Reports and Metadata\n",
    "Combine `report_*.json` and `metadata_*.json` and generate `merged_*.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c108d59-231a-4084-9da5-54a5d5fe9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    id_prefix,\n",
    "    category,\n",
    "    metadata_file,\n",
    "    report_file,\n",
    "    merged_file\n",
    ") in RESOURCES:\n",
    "    \n",
    "    metadata_path = f'../output/{metadata_file}'\n",
    "    report_path = f'../output/{report_file}'\n",
    "    merged_path = f'../output/{merged_file}'\n",
    "    \n",
    "    f = open(metadata_path, 'r')\n",
    "    meta = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(report_path, 'r')\n",
    "    reports = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    for report in reports:\n",
    "\n",
    "        BA_ID = report[ID_COLUMN]\n",
    "        METRICS = ['error', 'contrast', 'alert']\n",
    "\n",
    "        row = {}\n",
    "        row[ID_COLUMN] = BA_ID\n",
    "\n",
    "        # TODO: Improve the code below\n",
    "        for m in meta:\n",
    "            if m[ID_COLUMN] == BA_ID:\n",
    "                for key in m:\n",
    "                    row[key] = m[key]\n",
    "        \n",
    "        for metric in METRICS:\n",
    "            if report['report']['status']['success'] == False:\n",
    "                continue\n",
    "\n",
    "            scores = report['report']['categories'][metric]['items']\n",
    "\n",
    "            row['issue_type'] = metric\n",
    "\n",
    "            if len(scores) == 0:\n",
    "                # Add an explit zero-issue row\n",
    "                row_copy = row.copy()\n",
    "                row_copy['issue_id'] = f'{metric}None'\n",
    "                row_copy['issue_count'] = 0\n",
    "                row_copy['issue_desc'] = 'No Issues Found'\n",
    "                issues.append(row_copy)\n",
    "            else:\n",
    "                for score_category in scores:\n",
    "                    issue_id = scores[score_category]['id']\n",
    "                    issue_desc = scores[score_category]['description']\n",
    "                    issue_count = scores[score_category]['count']\n",
    "\n",
    "                    row_copy = row.copy()\n",
    "                    row_copy['issue_id'] = issue_id\n",
    "                    row_copy['issue_count'] = issue_count\n",
    "                    row_copy['issue_desc'] = issue_desc\n",
    "\n",
    "                    issues.append(row_copy)\n",
    "\n",
    "    merged = pd.DataFrame.from_records(issues)\n",
    "    merged.to_json(merged_path, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43782436-dca6-48be-ae4b-4b018ddca0ce",
   "metadata": {},
   "source": [
    "# Make Columns and Values Readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfc8e3-bdd8-43f0-b981-5387c744db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    id_prefix,\n",
    "    category,\n",
    "    metadata_file,\n",
    "    report_file,\n",
    "    merged_file\n",
    ") in RESOURCES:\n",
    "    path = f'../output/{merged_file}'\n",
    "    df = pd.read_json(path)\n",
    "    \n",
    "    # not ideal, but let's change the column names here at once\n",
    "    # print(df.columns)\n",
    "    columns = {\n",
    "        'BA_ID': 'baId', \n",
    "        'issue_type': 'issueType',\n",
    "        'issue_id': 'issueId', \n",
    "        'issue_count': 'issueCount', \n",
    "        'issue_desc': 'issueDesc',\n",
    "        'Sourceid': 'sourceId',\n",
    "        'Rank': 'rank',\n",
    "        'Title': 'title',\n",
    "        'Type': 'type',\n",
    "        'Issn': 'issn',\n",
    "        'SJR': 'sjr',\n",
    "        'SJR Best Quartile': 'sjrBestQuartile',\n",
    "        'H index': 'hIndex',\n",
    "        'Total Docs. (2021)': 'totalDocs2021',\n",
    "        'Total Docs. (3years)': 'totalDocs3Years',\n",
    "        'Total Refs.': 'totalRefs', \n",
    "        'Total Cites (3years)': 'totalCites3Years',\n",
    "        'Citable Docs. (3years)': 'citableDocs3Years',\n",
    "        'Cites / Doc. (2years)': 'citesOverDoc2Years',\n",
    "        'Ref. / Doc.': 'refOverDoc',\n",
    "        'Country': 'country',\n",
    "        'Region': 'region',\n",
    "        'Publisher': 'publisher',\n",
    "        'Coverage': 'coverage',\n",
    "        'Categories': 'categories',\n",
    "        'Areas': 'areas',\n",
    "        'github_stars': 'githubStars',\n",
    "        'alt_url': 'altUrl'\n",
    "    }\n",
    "    df = df.rename(columns=columns)\n",
    "    df.to_json(path, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cec8f-9aea-4512-8751-bf9e46cd0bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8bb4566648421152eab2c80a99b41c941f20a9702b17bc00f67120c6c73c42c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
