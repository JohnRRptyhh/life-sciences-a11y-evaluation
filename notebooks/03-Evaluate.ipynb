{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea9b39-afaa-4d27-b1bb-733b6accbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from constants import EVALUATION_DATE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f309c9-1d1d-4f09-b6ae-a277bf7bf994",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729be2b3-3f27-44d2-8074-424a7edd3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a WAVE API key stored in a local file\n",
    "with open('../input/api.lab.key', 'r') as f:\n",
    "    API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Portals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get filtered resources' page URLs and page IDs\n",
    "\"\"\"\n",
    "df_pages = pd.read_csv(os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'data-portal_pages.csv'))\n",
    "df_map = pd.read_csv(os.path.join('..', 'output', 'data-portal_id_map.csv'))\n",
    "\n",
    "# Get ids to filter by. Let's just look at the manually collected ones for now.\n",
    "# TODO: use the filtered data from `02-Filter.ipynb`!\n",
    "df_subpages = pd.read_csv(os.path.join('..', 'input', EVALUATION_DATE_FOLDER, 'URL Collection for Subpages - Data Portals.csv'))\n",
    "df_subpages.source_id = 'dc_' + df_subpages.source_id.astype(str) \n",
    "df_subpages = df_subpages.merge(df_map[['source_id', 'id']], on=['source_id'], how='left')\n",
    "FILTER_IDS = list(set(df_subpages.id.values.tolist()))\n",
    "\n",
    "# Filter pages by selected IDs. Also, empty URLs are excluded.\n",
    "df_pages = df_pages[(df_pages.id.isin(FILTER_IDS)) & (~df_pages.url.isnull())]\n",
    "\n",
    "# df_pages = df_pages.head(1) # for debuging purposes\n",
    "df_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf8b75-efb2-427c-88f2-e3f93f3037b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect raw reports all together first using API calls\n",
    "\"\"\"\n",
    "def collect_raw_reports_and_save(df_pages):\n",
    "\n",
    "    RAW_REPORTS_FOLDER = os.path.join('..', 'output', EVALUATION_DATE_FOLDER, 'raw-reports')\n",
    "    \n",
    "    # Create a folder to store raw reports, if missing\n",
    "    Path(RAW_REPORTS_FOLDER).mkdir(exist_ok=True)\n",
    "\n",
    "    \"\"\" \n",
    "    Collect missing reports one by one, and save them as a file\n",
    "    \"\"\"\n",
    "    for _, row in df_pages.iterrows():\n",
    "        page_id = row.page_id\n",
    "        url = row.url\n",
    "\n",
    "        # Skip if the report already exists\n",
    "        PAGE_REPORT_PATH = os.path.join(RAW_REPORTS_FOLDER, f'{page_id}.json')\n",
    "        is_exist = os.path.isfile(PAGE_REPORT_PATH)\n",
    "\n",
    "        if is_exist:\n",
    "            print(f'Report for {url} already exists. Skipping ...')\n",
    "            continue\n",
    "        \n",
    "        # Refer to https://wave.webaim.org/api/docs#!/request/getRequest for the API documentation\n",
    "        API_URL = f'https://wave.webaim.org/api/request?key={API_KEY}&reporttype=2&url={url}'\n",
    "        \n",
    "        print(f'Retrieving {url} ...')\n",
    "\n",
    "        try:\n",
    "            with urllib.request.urlopen(API_URL) as f:\n",
    "                new_report = json.load(f) # Refer to `../output/raw-reports-examples` to understand the structure of the report\n",
    "\n",
    "                # Save the raw report\n",
    "                with open(PAGE_REPORT_PATH, 'w') as f:\n",
    "                    json.dump(new_report, f)\n",
    "        except:\n",
    "            print('Failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_raw_reports_and_save(df_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405991a-a200-406e-9552-0c16f2269a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for args in RESOURCES:\n",
    "    collect_raw_reports_and_save(\n",
    "        get_sampled_resources_metadata(*args), \n",
    "        *args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6a393-d9b6-4d3d-9064-808256eb11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issues By Site\n",
    "\"\"\"\n",
    "issues = []\n",
    "with open('../output/accessibility-reports.json', 'r') as f:\n",
    "    reports = json.load(f)\n",
    "    for report in reports:\n",
    "        metrics = ['error', 'contrast', 'alert']\n",
    "        for m in metrics:\n",
    "            if report['report']['status']['success'] == False:\n",
    "                continue\n",
    "\n",
    "            stats = report['report']['categories'][m]['items']\n",
    "\n",
    "            row = {}\n",
    "            row['dbId'] = report['dbId']\n",
    "            row['shortName'] = report['shortName']\n",
    "            row['url'] = report['url']\n",
    "            row['type'] = m\n",
    "\n",
    "            for e in stats:\n",
    "                name = stats[e]['id']\n",
    "                count = stats[e]['count']\n",
    "                row_copy = row.copy()\n",
    "                row_copy['name'] = name\n",
    "                row_copy['count'] = count\n",
    "                \n",
    "                issues.append(row_copy)\n",
    "\n",
    "issues = pd.DataFrame.from_records(issues)\n",
    "issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916d510-f6f9-480b-b43c-66a039e07ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Site Metadata\n",
    "\"\"\"\n",
    "sites = pd.read_json('../input/database-commons-with-status.json')\n",
    "sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ce72c-5b31-4f5f-8c1d-b8d8a256d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge\n",
    "\"\"\"\n",
    "df_pages = issues.set_index(\"dbId\").join(sites.set_index(\"dbId\").drop(columns=['shortName', 'url'])).reset_index()\n",
    "df_pages.to_json('../output/accessibility-reports-with-metadata.json', orient='records')\n",
    "df_pages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03734762-d88c-4b80-81f4-318052b72c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Cleaning\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "cdf = df_pages.copy()\n",
    "\n",
    "def json_to_str(x, k):\n",
    "    if isinstance(x, float):\n",
    "        return x\n",
    "    else:\n",
    "        values = list(map((lambda _: _[k]), x))\n",
    "        values.sort()\n",
    "        return ', '.join(values)\n",
    "    \n",
    "multi_label_columns = [\n",
    "    ('dataTypeList', 'datatypeName'), \n",
    "    ('categoryList', 'name'), \n",
    "    ('keywordsList', 'name'),\n",
    "    ('dataObjectList', 'name'),\n",
    "#     ('ratingList', 'name'),\n",
    "    ('organismList', 'organismName'),\n",
    "    \n",
    "]\n",
    "\n",
    "for (c, k) in multi_label_columns:\n",
    "    cdf[c] = cdf[c].apply(lambda x: json_to_str(x, k))\n",
    "\n",
    "cdf = cdf.drop(columns=['ratingList', 'biodbRanks'])\n",
    "    \n",
    "cdf.to_json('../output/a11y-reports-with-metadata.json', orient='records')\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b42278-4dd2-432b-b434-cb3b68fee67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "life-sciences-a11y-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
