%load_ext autoreload
%autoreload 2
%aimport theme
import pandas as pd
import altair as alt
from altair import datum
from theme import apply_theme
alt.data_transformers.disable_max_rows(); # Allow using rows more than 5000





TIME_STAMP_FOLDER = 'JAN-10-2024'
A11Y_CATEGORIES = [
    ('dp', 'data-portal', 'Data Portals', 'short_name', 'url'),
    ('jp', 'journal-portal', 'Journal Portals', 'title', 'url'),
    ('go', 'gov', "US Government Websites", 'name', 'name')
]
TOP_CNT = 10 # for printing top websites





issues_df = pd.DataFrame()
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = pd.read_csv(
        f'../javascript/{TIME_STAMP_FOLDER}/{category}_a11y_issues.csv',
        header=None,
        names=['id', 'impact', 'description']
    )
    issues_df = pd.concat([issues_df, _])
issues_df.drop_duplicates(inplace=True)
issues_df.to_csv(f'../javascript/{TIME_STAMP_FOLDER}/all_a11y_issues.csv', index=False)
issues_df


issues_df[issues_df.impact == 'serious']


ISSUE_IDS = issues_df.id.tolist()


issues_df[issues_df.description.str.contains('alternate')]
ALT_ISSUE_IDS = issues_df[issues_df.description.str.contains('alternate')].id.tolist()
ALT_ISSUE_IDS





A11Y_CATEGORY = A11Y_CATEGORIES[0]


df = {}

for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    df[id] = pd.read_csv(
        f'../javascript/{TIME_STAMP_FOLDER}/{category}_a11y_results.csv',
        header=None,
        names=['page_id', 'issue_id', 'violations', 'passes']
    )

df['dp']








nei = pd.read_csv(
    f'../javascript/{TIME_STAMP_FOLDER}/nei-data-portal_a11y_results.csv',
    header=None,
    names=['page_id', 'issue_id', 'violations', 'passes']
)
df['dp'] = pd.concat([df['dp'], nei])
df['dp']





nih = pd.read_csv(
    f'../javascript/{TIME_STAMP_FOLDER}/nih-data-portal_a11y_results.csv',
    header=None,
    names=['page_id', 'issue_id', 'violations', 'passes']
)
df['dp'] = pd.concat([df['dp'], nih])
df['dp']





len(df['dp'].page_id.unique().tolist())





for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = df[id].copy()
    
    # To group by page_id, uncomment the following lines
    # _df.drop(['issue_id'], axis=1, inplace=True)
    # _df = _df.groupby(['page_id']).sum().reset_index()
    
    _['total_checks'] = _['violations'] + _['passes']
    _['failure_rate'] = _['violations'] / _['total_checks']
    df[id] = _
df['dp'].head(5)





for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = df[id].copy()
    
    # CHECKING...
    _ = _[_.issue_id != 'region']

    _.drop(['issue_id'], axis=1, inplace=True)
    _ = _.groupby(['page_id']).sum().reset_index()
    _['failure_rate'] = _['violations'] / _['total_checks']
    df[id + 'g'] = _
df['dpg'].head(5)


# for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
#     print(id, len(df[id + 'g'][name_field].unique().tolist()))





for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = df[id].copy()
    _ = _[_['issue_id'].isin(ALT_ISSUE_IDS)]
    _.drop(['issue_id'], axis=1, inplace=True)
    _ = _.groupby(['page_id']).sum().reset_index()
    _['failure_rate'] = _['violations'] / _['total_checks']
    df[id + 'ag'] = _
df['dpg'].head(5)





for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if(category == 'gov'):
        continue

    for ver in ['', 'g', 'ag']:
        _ = df[id + ver].copy()
        _['id'] = _['page_id'].apply(lambda x: x.split('_')[0])
        meta = pd.read_csv(f'../output/Nov-21-2023/{category}_metadata.csv')

        _['id'] = _['id'].astype(str)
        meta['id'] = meta['id'].astype(str)

        _ = _.merge(meta, left_on='id', right_on='id', how='left')

        # Some data cleaning
        if id == 'dp':
            # Group NIH 
            NIH_INSTS = [
                'National Center for Biotechnology Information',
                'National Cancer Institute',
                'National Heart, Lung, and Blood Institute',
                'National Center for Advancing Translational Sciences',
                'National Institutes of Health',
                'National Human Genome Research Institute',
                'National Institute of Environmental Health Sciences',
                'National Library of Medicine',
                'National Institute of Standards and Technology',
                'National Institute of Health',
                'National Institute on Aging',
                'National Institute of Neurological Disorders & Stroke',
                'National Institute of Child Health and Human Development',
                'National Eye Institute', # none found
                'National Institute of Allergy and Infectious Diseases',
                'National Institute of Arthritis and Musculoskeletal and Skin Diseases'
            ]
            _.loc[_.host_institution.isin(NIH_INSTS), 'host_institution'] = 'National Institutes of Health'
        # elif id == 'jp':
            # _.loc[_.publisher.str.contains('Elsevier') == True, 'publisher'] = 'Elsevier'
            # _.loc[_.publisher.str.contains('Springer') == True, 'publisher'] = 'Springer-related'

        df[id + ver] = _
df['jpag'].head(5)





# Special treatments
# for gov
gov_meta = pd.read_csv(f'../javascript/{TIME_STAMP_FOLDER}/gov_pages.csv', sep=',', header=None, names=['name', 'type', 'inst', 'desc', 'city', 'state', 'blank'])
gov_meta.reset_index(inplace=True)
df['gog'] = df['gog'].merge(gov_meta, left_on='page_id', right_on='index', how='left')
df['gog']['url'] = df['gog']['name']





# Add metadata to NEI data portals
_meta = pd.read_csv(f'../javascript/{TIME_STAMP_FOLDER}/nei-data-portal_pages.csv')
_meta.set_index('page_id', inplace=True)
_ = df['dpg'].copy()
_.set_index('page_id', inplace=True)
_[_.isnull()] = _meta
_.reset_index(inplace=True)
_[_.page_id.str.contains('nei')]
df['dpg'] = _


# Add metadata to NIH data portals
_meta = pd.read_csv(f'../javascript/{TIME_STAMP_FOLDER}/nih-data-portal_pages.csv')
_meta['short_name'] = _meta.Repository_Name
_meta['host_institution'] = 'National Institutes of Health'
_meta['country'] = 'United States'
_meta.set_index('page_id', inplace=True)
_ = df['dpg'].copy()
_.set_index('page_id', inplace=True)
_[_.isnull()] = _meta
_.reset_index(inplace=True)
_[_.page_id.str.contains('nei')]
df['dpg'] = _








df['dpg'].country = df['dpg'].country.apply(lambda x: "South Korea" if x == 'Korea Republic of' else "Russia" if x == 'Russian Federation' else x)





_ = pd.read_csv(f'../javascript/{TIME_STAMP_FOLDER}/Publishers of Journal Portals - Sheet1.csv')
_.Cleaned.fillna(_.Original, inplace=True)
mapping = dict(zip(_.Original, _.Cleaned))

df['jpg'].publisher = df['jpg'].publisher.apply(lambda x: mapping[x] if x in mapping else x)
df['jpg'].head(5)





_ = pd.read_csv(f'../javascript/{TIME_STAMP_FOLDER}/Filtering of Journals - Sheet1.csv')
_.rename(columns={'If filter "v", otherwise empty': 'is_filter'}, inplace=True)
_.is_filter = _.is_filter.apply(lambda x: True if x == 'v' else False)
mapping = dict(zip(_.Title, _.is_filter))
mapping
df['jpg']['is_filter'] = df['jpg'].title.apply(lambda x: mapping[x] if x in mapping else False)
df['jpg'] = df['jpg'][df['jpg'].is_filter == True]
df['jpg']





from datetime import date
from pathlib import Path

# To share the data with collaborators:
for key in ['jpg', 'dpg', 'gog']:
    file_name = 'journal-websites' if key == 'jpg' else 'data-portals' if key == 'dpg' else 'us-goverment-websites'
    today = date.today()
    folder = f'../output/share/{today}'
    Path(folder).mkdir(parents=True, exist_ok=True)
    df[key].to_csv(f'{folder}/{file_name}_{today}.csv', index=False)


# _ = df['jpag'][['title', 'areas', 'url']]
# _.to_clipboard()


# Columns with list of values
COLUMNS_WITH_LIST = list(filter(lambda x: 'list' in x, df['dpag'].columns))
df['dpg'][['short_name'] + COLUMNS_WITH_LIST].head(10)


# Columns with list of values
df['jpg'][['title', 'categories', 'areas']].head(10)


US_GOV_FR_MEAN = df['gog'].failure_rate.mean()
US_GOV_FR_MEAN


df['jpg'].columns


# Unique categories
df['jpg'].areas.str.split('; ', expand=True).stack().unique().tolist()


# Unique categories
_ = df['dpg'].copy()
_[_.host_institution == 'National Eye Institute']


len(df['gog'].page_id.unique().tolist())


# Numb of unique countries
len([x for x in list(set(df['dpg'].country.tolist() + df['jpg'].country.unique().tolist())) if str(x) != 'nan'])


# Numb of jorunal publishers
len(df['jpg'].publisher.unique().tolist())


# Numb of data portal institutions
len(df['dpg'].host_institution.unique().tolist())





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    bests = df[id + 'g'].sort_values(by='failure_rate', ascending=True).head(TOP_CNT)[name_field].tolist()
    worsts = df[id + 'g'].sort_values(by='failure_rate', ascending=False).head(TOP_CNT)[name_field].tolist()
    print(f"{title}' Best:")
    print(f"\t{', '.join(bests)}")
    print(f"{title}' Worst:")
    print(f"\t{', '.join(worsts)}")
    _ = (
        alt.Chart(
            df[id + 'g'][df[id + 'g'].failure_rate > 0]
        ).mark_bar(
            # opacity=0.01
            color='#56B4E9'
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').bin(extent=[0, 1], step=0.01).scale(domain=[0, 0.5], clamp=True).axis(format='%'),
            alt.Y('count()', title="The Number of Websites").scale(type='linear'),
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            height=300,
            width=500
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.X(f'baseline:Q', title='Failure Rate'),
            y=alt.Y()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.properties(
    title={
        'text': 'The Distribution of Failure Rate of Webpages',
        'subtitle': '* Dashed line represents the average failure rate of US government websites',
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)





CUT = 10
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    print(title)
    print('Bottom ' + str(CUT))
    print(df[id + 'g'].sort_values(by=['failure_rate'], ascending=False).head(CUT)[url_field].tolist())
    print('Top ' + str(CUT))
    print(df[id + 'g'].sort_values(by=['failure_rate'], ascending=True).head(CUT)[url_field].tolist())

    # This shows that we really need to filter data properly!
    # There are many 404 pages in the data





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    bests = df[id + 'g'].sort_values(by='total_checks', ascending=True).head(TOP_CNT)[name_field].tolist()
    worsts = df[id + 'g'].sort_values(by='total_checks', ascending=False).head(TOP_CNT)[name_field].tolist()
    print(f"{title}' Lowest:")
    print(f"\t{', '.join(bests)}")
    print(f"{title}' Highest:")
    print(f"\t{', '.join(worsts)}")
    _ = (
        alt.Chart(
            df[id + 'g']
        ).mark_bar(
            # opacity=0.3,
            color='#56B4E9',
            # stroke='black'
        ).encode(
            alt.X(f'total_checks:Q', title='The Number of DOM Elements').bin(extent=[0, 10000], step=100).scale(padding=0, type='linear', domain=[0, 3200], clamp=True),
            alt.Y('count()', title='The Number of Websites').scale(type='linear'),
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            height=300,
            width=500
        )
    )
    
    plot = _ if plot is None else plot | _

plot = plot.properties(
    title='The Distribution of the Number of DOM Elements'
)

apply_theme(plot)





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = (
        alt.Chart(
            df[id + 'g']
        ).mark_point(
            filled=True,
            opacity=0.3,
            color='#56B4E9'
        ).encode(
            alt.X(f'total_checks:Q', title='The Number of DOM Elements').scale(type='log'),
            alt.Y('failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]),
            alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        ).properties(
            title={
                'text': title,
                'color': 'grey'
            },
            width=400,
            height=300
        )
    )
    
    nei = _.transform_filter(datum.host_institution == 'National Eye Institute').mark_point(
        opacity=1,
        filled=True,
        color='#D55D00'    
    )

    nih = _.transform_filter(datum.host_institution == 'National Institutes of Health').mark_point(
        opacity=1,
        filled=True,
        color='#009E73'    
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.Y(f'baseline:Q', title='Failure Rate'),
            alt.X()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = _ + nih + nei + baseline

    plot = _ if plot is None else plot | _

plot = plot.properties(
    title={
        'text': 'The Number of Items Checked vs. Failure Rate',
        'subtitle': '* Dashed line represents the average failure rate of US government websites',
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue
    
    impact_field = 'h_index' if id == 'jp' else 'citation'

    _ = (
        alt.Chart(
            df[id + 'g']
        ).mark_point(
            # filled=True,
            opacity=0.3,
            color='#56B4E9'
        ).encode(
            alt.X(f'{impact_field}:Q', title=impact_field.capitalize()),#,.scale(type='log'),
            alt.Y('failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]),
            alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        ).properties(
            title={
                'text': title,
                'color': 'grey'
            },
            width=400,
            height=300
        )
    )

    t = (
        alt.Chart(
            df[id + 'g'][df[id + 'g'][impact_field] > (10000 if id == 'dp' else 800)]
        ).mark_text(
            align='left',
            limit=200,
            opacity=0.5,
            fontSize=14,
            dx=10,
            baseline='bottom'
        ).encode(
            alt.X(f'{impact_field}:Q', title=impact_field.capitalize()),#,.scale(type='log'),
            alt.Y('failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]),
            alt.Text(f'{name_field}:N'),
            alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.Y(f'baseline:Q', title='Failure Rate'),
            alt.X()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.properties(
    title='Failure Rate by Impact Score of Each Website'
)

apply_theme(plot)





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue
    
    impact_field = 'h_index' if id == 'jp' else 'citation'
    gropu_field = 'publisher' if id == 'jp' else 'host_institution'

    _ = (
        alt.Chart(
            df[id + 'g']
        ).mark_point(
            # filled=True,
            opacity=0.3,
            color='#56B4E9'
        ).encode(
            alt.X(f'mean({impact_field}):Q', title=impact_field.capitalize()),#,.scale(type='log'),
            alt.Y('mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 1]),
            alt.Color(f'{gropu_field}:N').scale(range=['#56B4E9']),
            alt.Tooltip([f'{gropu_field}:N'])
            # alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        ).properties(
            title={
                'text': title,
                'color': 'grey'
            },
            width=400,
            height=300
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.Y(f'baseline:Q', title='Failure Rate'),
            alt.X(),
            alt.Color()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.properties(
    title='Failure Rate by Impact Score of Each Website'
)

apply_theme(plot)





plots = []
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = (
        alt.Chart(
            df[id][df[id].issue_id != 'region']
        ).mark_bar(
            color='#56B4E9'
        ).encode(
            alt.Y('issue_id:N'),
            alt.X(f'sum(total_checks):Q', title='The Number of Items Checked'),#.scale(type='log'),
            alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        ).properties(
            title={
                'text': title,
                'color': 'grey'
            },
            width=400,
            height=1000
        )
    )
    plots.append(_)

# plot = plot.properties(
#     title='The Number of Items Checked vs. Failure Rate'
# )
    
plot = alt.hconcat(*plots).resolve_scale(y='independent')

apply_theme(plot)





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue

    # Select Countries with more than 10 pages
    CUT = 100
    _ = df[id + 'g'].copy()
    df_count = _.country.value_counts().reset_index().sort_values(by='count', ascending=False)
    df_count = df_count[df_count['count'] > CUT]
    COUNTRY_FILTER = df_count.country.tolist()

    _ = (
        alt.Chart(
            _[_.country.isin(COUNTRY_FILTER)]
        ).mark_bar(
            # opacity=0.01
            color='#56B4E9'
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').bin(extent=[0, 1], step=0.01).scale(domain=[0, 1]).axis(format='%'),
            alt.Y('count()').scale(type='linear'),
            alt.Row('country:N', sort=['United States', 'China'])
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            height=100,
            width=500
        )
    )
    plot = _ if plot is None else plot | _

plot = plot.resolve_axis(y='independent')

plot = plot.properties(
    title={
        'text': 'The Distribution of Failure Rate of Webpages by Country',
        'subtitle': f'Only countries with more than {CUT} pages are shown',
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)


plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue

    # Select Countries with more than 10 pages
    CUT = 10
    _ = df[id + 'g'].copy()
    df_count = _.country.value_counts().reset_index().sort_values(by='count', ascending=False)
    df_count = df_count[df_count['count'] > CUT]
    COUNTRY_FILTER = df_count.country.tolist()

    # Sort
    df_fr = _[_.country.isin(COUNTRY_FILTER)][['country', 'failure_rate']].groupby(['country']).mean().reset_index().sort_values(by='failure_rate', ascending=False)
    COUNTRY_SORT = df_fr.country.tolist()

    _ = (
        alt.Chart(
            _[_.country.isin(COUNTRY_FILTER)]
        ).mark_tick(
            # opacity=0.01
            color='#D20000',
            thickness=2,
            size=20
        ).encode(
            alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y('country:N', sort=COUNTRY_SORT)
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            height=500,
            width=500
        )
    )

    dist = (
        _.mark_circle(
            color='grey',
            size=10,
            opacity=0.5
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y('country:N', sort=COUNTRY_SORT),
            alt.YOffset('jitter:Q')
        ).transform_calculate(
            jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.X(f'baseline:Q', title='Failure Rate'),
            y=alt.Y()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = (dist + _ + baseline).resolve_axis(y='shared')

    plot = _ if plot is None else plot | _

plot = plot.resolve_axis(y='independent')

plot = plot.properties(
    title={
        'text': 'The Failure Rate of Webpages by Country Compared to Baseline',
        'subtitle': [
            f'* Only countries with more than {CUT} pages are shown',
            '* US Government websites are used as the baseline (dashed line)'
        ],
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)





plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue
    
    category_field = 'publisher' if id == 'jp' else 'host_institution'
    
    _ = df[id + 'g'].copy()

    # Select Countries with more than 10 pages
    CUT = 10
    df_count = _[category_field].value_counts().reset_index().sort_values(by='count', ascending=False)
    df_count = df_count[df_count['count'] > CUT]
    FILTER = df_count[category_field].tolist()

    # Sort
    df_fr = _[_[category_field].isin(FILTER)][[category_field, 'failure_rate']].groupby([category_field]).mean().reset_index().sort_values(by='failure_rate', ascending=False)
    SORT = df_fr[category_field].tolist()

    _ = (
        alt.Chart(
            _[_[category_field].isin(FILTER)]
        ).mark_tick(
            # opacity=0.01
            color='#D20000',
            thickness=2,
            # size=500 / len(COUNTRY_SORT),
        ).encode(
            alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y(f'{category_field}:N', sort=SORT, title=None)
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            # height=500,
            width=500
        )
    )

    dist = (
        _.mark_circle(
            color='grey',
            size=20,
            opacity=0.5
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y(f'{category_field}:N', sort=SORT, title=None),
            alt.YOffset('jitter:Q'),
            alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        ).transform_calculate(
            jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.X(f'baseline:Q', title='Failure Rate'),
            y=alt.Y()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = dist + _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.resolve_axis(y='independent')

plot = plot.properties(
    title={
        'text': 'The Failure Rate of Webpages by Organization Compared to Baseline',
        'subtitle': [
            f'* Only publishers/institutions with {CUT} pages or more are shown',
            '* US Government websites are used as the baseline (Dashed Line)'
        ],
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)


_ = df['dpg']
_[_.host_institution == 'National Center for Biotechnology Information'].sort_values(by='failure_rate', ascending=True).short_name





name_field = 'short_name'
category_field = 'host_institution'

_ = df['dpg'].copy()

_ = _[_.host_institution.isin(NIH_INSTS)]

# Select Countries with more than 10 pages
CUT = 1
df_count = _[category_field].value_counts().reset_index().sort_values(by='count', ascending=False)
df_count = df_count[df_count['count'] > CUT]
FILTER = df_count[category_field].tolist()

# Sort
df_fr = _[_[category_field].isin(FILTER)][[category_field, 'failure_rate']].groupby([category_field]).mean().reset_index().sort_values(by='failure_rate', ascending=False)
SORT = df_fr[category_field].tolist()

_ = (
    alt.Chart(
        _[_[category_field].isin(FILTER)]
    ).mark_tick(
        # opacity=0.01
        color='#D20000',
        thickness=2,
        # size=500 / len(COUNTRY_SORT),
    ).encode(
        alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
        alt.Y(f'{category_field}:N', sort=SORT, title=None)
    ).properties(
        title={
            "text": title,
            "color": "grey"
        },
        # height=500,
        width=500
    )
)

dist = (
    _.mark_circle(
        color='grey',
        size=20,
        opacity=0.5
    ).encode(
        alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
        alt.Y(f'{category_field}:N', sort=SORT, title=None),
        alt.YOffset('jitter:Q'),
        alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
    ).transform_calculate(
        jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
    )
)

baseline = (
    _.mark_rule(
        color='black',
        size=2,
        # size=500 / len(COUNTRY_SORT),
        strokeDash=[4, 2]
    ).encode(
        alt.X(f'baseline:Q', title='Failure Rate'),
        y=alt.Y()
    ).transform_calculate(
        baseline=f"{US_GOV_FR_MEAN}"
    )
)

_ = dist + _ + baseline

plot = _

plot = plot.properties(
    title={
        'text': 'The Failure Rate of NIH Data Portals Compared to Baseline',
        'subtitle': [
            '* US Government websites are used as the baseline (Dashed Line)'
        ],
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)





alt.Chart(
    df['dp'][df['dp'].host_institution == 'National Institutes of Health']
).mark_bar(
    color='#56B4E9'
).encode(
    alt.Y('issue_id:N'),
    alt.X(f'mean(failure_rate):Q', title='The Number of Items Checked'),#.scale(type='log'),
).properties(
    title={
        'text': title,
        'color': 'grey'
    },
    width=400,
    height=1000
)





id = 'dp'
_df = df[id + 'g'][df[id + 'g'].failure_rate > 0].copy()
dotgov = _df[_df.url.str.contains('.gov')]
all = (
    alt.Chart(
        _df
    ).mark_bar(
        color='#56B4E9'
    ).encode(
        alt.X(f'failure_rate:Q', title='Failure Rate').bin(extent=[0, 1], step=0.01).scale(domain=[0, 0.5], clamp=True).axis(format='%'),
        alt.Y('count()', title="The Number of Websites").scale(type='linear'),
    ).properties(
        title={
            "text": title,
            "color": "grey"
        },
        height=300,
        width=500
    )
)

onlydotgov = (
    alt.Chart(
        dotgov
    ).mark_bar(
        # opacity=0.01
        color='#0072B2'
    ).encode(
        alt.X(f'failure_rate:Q', title='Failure Rate').bin(extent=[0, 1], step=0.01).scale(domain=[0, 0.5], clamp=True).axis(format='%'),
        alt.Y('count()', title="The Number of Websites").scale(type='linear'),
    ).properties(
        title={
            "text": title,
            "color": "grey"
        },
        height=300,
        width=500
    )
)

baseline = (
    all.mark_rule(
        color='black',
        size=2,
        # size=500 / len(COUNTRY_SORT),
        strokeDash=[4, 2]
    ).encode(
        alt.X(f'baseline:Q', title='Failure Rate'),
        y=alt.Y()
    ).transform_calculate(
        baseline=f"{US_GOV_FR_MEAN}"
    )
)

_ = all + onlydotgov + baseline
_
_ = _.properties(
    title={
        'text': 'The Distribution of Failure Rate of Data Portals',
        'subtitle': [
            '* Dashed line represents the average failure rate of US government websites',
            '* Dark blue bars represent .gov websites'
        ],
        'subtitleColor': 'grey'
    }
)
apply_theme(_)





df['dpg']['resource_type'] = 'Data Portals'
df['jpg']['resource_type'] = 'Journal Portals'
df['gog']['resource_type'] = 'Government Websites'
merged = pd.concat([df['dpg'], df['jpg'], df['gog']])
merged['is_dot_gov'] = merged['url'].apply(lambda x: '.gov' if '.gov' in x.lower() else 'None-.gov')


_ = (
    alt.Chart(
        merged
    ).mark_tick(
        color='#D20000',
        thickness=2,
        size=100
    ).encode(
        alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 0.5], clamp=True).axis(format='%'),
        alt.Y('is_dot_gov:N', title=None)
    ).properties(
        title={
            "text": title,
            "color": "grey"
        },
        height=300,
        width=500
    )
)

dist = (
    _.mark_circle(
        color='grey',
        size=20,
        opacity=0.5
    ).encode(
        alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, .5], clamp=True).axis(format='%'),
        alt.Y(f'is_dot_gov:N', title=None),
        alt.YOffset('jitter:Q'),
        alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
    ).transform_calculate(
        jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
    )
)

baseline = (
    _.mark_rule(
        color='black',
        size=2,
        strokeDash=[4, 2]
    ).encode(
        alt.X(f'baseline:Q', title='Failure Rate'),
        y=alt.Y()
    ).transform_calculate(
        baseline=f"{US_GOV_FR_MEAN}"
    )
)

plot = dist + _ + baseline

plot = plot.properties(
    title="The Failure Rate of All Websites By Domain"
)

apply_theme(plot)


_ = (
    alt.Chart(
        merged[merged.resource_type == 'Data Portals']
    ).mark_tick(
        color='#D20000',
        thickness=2,
        size=100
    ).encode(
        alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 0.5], clamp=True).axis(format='%'),
        alt.Y('is_dot_gov:N', title=None)
    ).properties(
        title={
            "text": title,
            "color": "grey"
        },
        height=300,
        width=500
    )
)

dist = (
    _.mark_circle(
        color='grey',
        size=20,
        opacity=0.5
    ).encode(
        alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, .5], clamp=True).axis(format='%'),
        alt.Y(f'is_dot_gov:N', title=None),
        alt.YOffset('jitter:Q'),
        alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
    ).transform_calculate(
        jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
    )
)

baseline = (
    _.mark_rule(
        color='black',
        size=2,
        strokeDash=[4, 2]
    ).encode(
        alt.X(f'baseline:Q', title='Failure Rate'),
        y=alt.Y()
    ).transform_calculate(
        baseline=f"{US_GOV_FR_MEAN}"
    )
)

plot = dist + _ + baseline

plot = plot.properties(
    title="The Failure Rate of Data Portals By Domain"
)

apply_theme(plot)





_ = (
    alt.Chart(
        merged[merged.is_dot_gov == '.gov']
    ).mark_tick(
        color='#D20000',
        thickness=2,
        size=100
    ).encode(
        alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 0.5], clamp=True).axis(format='%'),
        alt.Y('resource_type:N', title=None)
    ).properties(
        title={
            "text": title,
            "color": "grey"
        },
        height=300,
        width=500
    )
)

dist = (
    _.mark_circle(
        color='grey',
        size=20,
        opacity=0.5
    ).encode(
        alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, .5], clamp=True).axis(format='%'),
        alt.Y(f'resource_type:N', title=None),
        alt.YOffset('jitter:Q'),
        alt.Tooltip([f'short_name:N', f'url:N'])
    ).transform_calculate(
        jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
    )
)

baseline = (
    _.mark_rule(
        color='black',
        size=2,
        strokeDash=[4, 2]
    ).encode(
        alt.X(f'baseline:Q', title='Failure Rate'),
        y=alt.Y()
    ).transform_calculate(
        baseline=f"{US_GOV_FR_MEAN}"
    )
)

plot = dist + baseline + _

plot = plot.properties(
    title="The Failure Rate of .gov Websites"
)

apply_theme(plot)





alt.Chart(
    # df['dpg']
    # or
    df['dpg'][df['dpg'].host_institution == 'National Institutes of Health']
).mark_bar(
    # opacity=0.01
).encode(
    alt.Y(f'mean(failure_rate):Q'),
    alt.X('founded_year:O'),
).properties(
    width=500
)





US_GOV_ALT_FR_MEAN = df['goag'].failure_rate.mean()
US_GOV_ALT_FR_MEAN


plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = (
        alt.Chart(
            df[id + 'ag'][df[id + 'ag'].failure_rate >= 0]
        ).mark_bar(
            # opacity=0.01
            color='#56B4E9'
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').bin(extent=[0, 1], step=0.01).scale(domain=[0, 1]).axis(format='%'),
            alt.Y('count()').scale(type='log'),
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            height=300,
            width=500
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.X(f'baseline:Q', title='Failure Rate'),
            alt.Y(),
            alt.Color()
        ).transform_calculate(
            baseline=f"{US_GOV_ALT_FR_MEAN}"
        )
    )
    
    _ = _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.properties(
    title='The Distribution of Failure Rate of Webpages'
)

apply_theme(plot)


plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue
    
    category_field = 'publisher' if id == 'jp' else 'host_institution'
    
    _ = df[id + 'ag'].copy()

    # Select Countries with more than 10 pages
    CUT = 10
    df_count = _[category_field].value_counts().reset_index().sort_values(by='count', ascending=False)
    df_count = df_count[df_count['count'] > CUT]
    FILTER = df_count[category_field].tolist()

    # Sort
    df_fr = _[_[category_field].isin(FILTER)][[category_field, 'failure_rate']].groupby([category_field]).mean().reset_index().sort_values(by='failure_rate', ascending=False)
    SORT = df_fr[category_field].tolist()

    _ = (
        alt.Chart(
            _[_[category_field].isin(FILTER)]
        ).mark_tick(
            # opacity=0.01
            color='#D20000',
            thickness=2,
            # size=500 / len(COUNTRY_SORT),
        ).encode(
            alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y(f'{category_field}:N', sort=SORT, title=None)
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            # height=500,
            width=500
        )
    )

    dist = (
        _.mark_circle(
            color='grey',
            size=20,
            opacity=0.5
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y(f'{category_field}:N', sort=SORT, title=None),
            alt.YOffset('jitter:Q'),
            alt.Tooltip([f'{name_field}:N', f'{url_field}:N'])
        ).transform_calculate(
            jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.X(f'baseline:Q', title='Failure Rate'),
            y=alt.Y()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = dist + _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.resolve_axis(y='independent')

plot = plot.properties(
    title={
        'text': 'The Failure Rate of Webpages by Organization Compared to Baseline',
        'subtitle': [
            f'* Only publishers/institutions with {CUT} pages or more are shown',
            '* US Government websites are used as the baseline (Dashed Line)'
        ],
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)


plot = None
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    if id == 'go':
        continue

    # Select Countries with more than 10 pages
    CUT = 10
    _ = df[id + 'ag'].copy()
    df_count = _.country.value_counts().reset_index().sort_values(by='count', ascending=False)
    df_count = df_count[df_count['count'] > CUT]
    COUNTRY_FILTER = df_count.country.tolist()

    # Sort
    df_fr = _[_.country.isin(COUNTRY_FILTER)][['country', 'failure_rate']].groupby(['country']).mean().reset_index().sort_values(by='failure_rate', ascending=False)
    COUNTRY_SORT = df_fr.country.tolist()

    _ = (
        alt.Chart(
            _[_.country.isin(COUNTRY_FILTER)]
        ).mark_tick(
            # opacity=0.01
            color='#D20000',
            thickness=2,
            size=22
        ).encode(
            alt.X(f'mean(failure_rate):Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y('country:N', sort=COUNTRY_SORT)
        ).properties(
            title={
                "text": title,
                "color": "grey"
            },
            height=500,
            width=500
        )
    )

    dist = (
        _.mark_circle(
            color='grey',
            size=10,
            opacity=0.5
        ).encode(
            alt.X(f'failure_rate:Q', title='Failure Rate').scale(domain=[0, 1]).axis(format='%'),
            alt.Y('country:N', sort=COUNTRY_SORT),
            alt.YOffset('jitter:Q')
        ).transform_calculate(
            jitter="sqrt(-2*log(random()))*cos(2*PI*random())"
        )
    )

    baseline = (
        _.mark_rule(
            color='black',
            size=2,
            # size=500 / len(COUNTRY_SORT),
            strokeDash=[4, 2]
        ).encode(
            alt.X(f'baseline:Q', title='Failure Rate'),
            y=alt.Y()
        ).transform_calculate(
            baseline=f"{US_GOV_FR_MEAN}"
        )
    )
    
    _ = dist + _ + baseline

    plot = _ if plot is None else plot | _

plot = plot.resolve_axis(y='independent')

plot = plot.properties(
    title={
        'text': 'The Failure Rate of Webpages by Country Compared to Baseline',
        'subtitle': [
            f'* Only countries with more than {CUT} pages are shown',
            '* US Government websites are used as the baseline (dashed line)'
        ],
        'subtitleColor': 'grey'
    }
)

apply_theme(plot)


plots = []
for (id, category, title, name_field, url_field) in A11Y_CATEGORIES:
    _ = (
        alt.Chart(
            df[id + 'g']
        ).mark_bar(
            # opacity=0.01
        ).encode(
            alt.X(f'mean(total_checks):Q'),
            alt.Y('country:N', sort='-x'),
            alt.Color('count()'),
            alt.Tooltip(['count()'])
        ).properties(
            title='Countries with more than 10 sites',
            width=500
        )
    )
    plots.append(_)
apply_theme(alt.vconcat(*plots))





alt.Chart(
    _df[_df.country.isin(COUNTRIES)]
).mark_bar(
    # opacity=0.01
).encode(
    alt.X(f'mean(A3):Q'),
    alt.Y('country:N', sort='-x'),
    alt.Color('count()'),
    alt.Tooltip(['count()'])
).properties(
    title='Countries with more than 10 sites',
    width=500
)


alt.Chart(
    _df[_df.country.isin(COUNTRIES)]
).mark_bar(
    # opacity=0.01
).encode(
    alt.X(f'mean(violation_ratio):Q', title='The ratio of violations among all potential violations').axis(format='.1%').scale(alt.Scale(domain=(0, 1))),
    alt.Y('country:N', sort='-x'),
    alt.Color('count()'),
    alt.Tooltip(['count()'])
).properties(
    title='Countries with more than 10 sites',
    width=500
)


df_host_institution_count = _df.host_institution.value_counts().reset_index().sort_values(by='count', ascending=False)
df_host_institution_count = df_host_institution_count[df_host_institution_count['count'] > 10]
INSTS = df_host_institution_count.host_institution.tolist()
INSTS


alt.Chart(
    _df[_df.host_institution.isin(INSTS)]
).mark_bar(
    # opacity=0.01
).encode(
    alt.X(f'mean(Np):Q'),
    alt.Y('host_institution:N', sort='-x'),
    alt.Color('count()'),
    alt.Tooltip(['count()'])
).properties(
    title='host_institution with more than 10 sites',
    width=500
)



